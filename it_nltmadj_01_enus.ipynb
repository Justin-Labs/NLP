{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2d65f912",
      "metadata": {
        "id": "2d65f912"
      },
      "source": [
        "\n",
        "## it_nltmadj_01_enus_04"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663a5b87",
      "metadata": {
        "id": "663a5b87"
      },
      "source": [
        "### WordNet with NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f8189a7",
      "metadata": {
        "id": "8f8189a7"
      },
      "source": [
        "**WordNet** is a database of English words that are linked together by their semantic relationships. It is like a supercharged dictionary/thesaurus with a graph structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7c7ad145",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c7ad145",
        "outputId": "494d0046-333c-4e16-e92b-64b2603b90ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\nukes\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "The WordNet is a part of Python's Natural Language Toolkit. It is a large word database of English Nouns, Adjectives, Adverbs \n",
        "and Verbs. These are grouped into some set of cognitive synonyms, which are called synsets.\n",
        "'''\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8ea565",
      "metadata": {
        "id": "9e8ea565"
      },
      "source": [
        "#### Synsets\n",
        "A synonym set, or synset, is a group of synonyms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "baa4292f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baa4292f",
        "outputId": "4a80ecca-97c0-425c-f546-fed23d1da38b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n"
          ]
        }
      ],
      "source": [
        "syn_arr = wordnet.synsets('good') # this is how to look up some word in wordnet, many different meanings of the words\n",
        "print(syn_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56ebecd4",
      "metadata": {
        "id": "56ebecd4"
      },
      "source": [
        "#### Definition \n",
        "Synsets also come with a prose **definition** and some **example** sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e3b16f84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e3b16f84",
        "outputId": "e3c2db54-99b8-41f8-d4e3-864156aafd34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'articles of commerce'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "syn_arr[3].definition() # We can check different definition for the word in synset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0dsbkpSVxS1g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dsbkpSVxS1g",
        "outputId": "63e72ec2-a0ea-43e5-f509-cae426ea7d81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['there is much good to be found in people']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "syn_arr[1].examples() # Returns an example sentence for the word. You can try for all the indexes from 0 to 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adbb7dc2",
      "metadata": {
        "id": "adbb7dc2"
      },
      "source": [
        "#### lemma\n",
        "The synonyms contained within a synset are called **lemmas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b4388609",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4388609",
        "outputId": "9a3e0a1a-7b78-420b-ea67-d200911ba6c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['good', 'goodness']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "syn_arr[1].lemma_names()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67f30dc2",
      "metadata": {
        "id": "67f30dc2"
      },
      "source": [
        "##### Synonyms and Antonyms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5034e7c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5034e7c9",
        "outputId": "219d15ba-12ad-4ad7-b831-f6454f2b5ae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synonyms: ['good', 'good', 'goodness', 'good', 'goodness', 'commodity', 'trade_good', 'good', 'good', 'full', 'good', 'good', 'estimable', 'good', 'honorable', 'respectable', 'beneficial', 'good', 'good', 'good', 'just', 'upright', 'adept', 'expert', 'good', 'practiced', 'proficient', 'skillful', 'skilful', 'good', 'dear', 'good', 'near', 'dependable', 'good', 'safe', 'secure', 'good', 'right', 'ripe', 'good', 'well', 'effective', 'good', 'in_effect', 'in_force', 'good', 'good', 'serious', 'good', 'sound', 'good', 'salutary', 'good', 'honest', 'good', 'undecomposed', 'unspoiled', 'unspoilt', 'good', 'well', 'good', 'thoroughly', 'soundly', 'good']\n",
            "Antonyms: ['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill']\n"
          ]
        }
      ],
      "source": [
        "# Creating a list of all the synonyms and antonyms for a particular word\n",
        "syn = list() # Empty synonyms list\n",
        "ant = list() # Empty antonyms list\n",
        "for synset in syn_arr: \n",
        "    for lemma in synset.lemmas():\n",
        "        syn.append(lemma.name())    #add the synonyms to the list\n",
        "        if lemma.antonyms():    #When antonyms are available, add them into the list\n",
        "            ant.append(lemma.antonyms()[0].name())\n",
        "print('Synonyms: ' + str(syn))\n",
        "print('Antonyms: ' + str(ant))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab8cad2",
      "metadata": {
        "id": "fab8cad2"
      },
      "source": [
        "#### Wordnet Hierarchy   \n",
        "\n",
        "We have seen, all synsets are connected to other synsets by means of semantic relations. It forms a hierarchy of concepts. \n",
        "\n",
        "That Hierarchy can be understood by two terminologies: \n",
        "\n",
        "- Hypernyms \n",
        "\n",
        "- Hyponyms "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "3917b8f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3917b8f8",
        "outputId": "983328d2-c863-48d7-8b5f-f1755e9268f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hypernyms:  [Synset('advantage.n.01')]\n",
            "Hyponyms:  [Synset('common_good.n.01')]\n"
          ]
        }
      ],
      "source": [
        "print('Hypernyms: ',syn_arr[0].hypernyms())\n",
        "print('Hyponyms: ',syn_arr[0].hyponyms())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba1946b2",
      "metadata": {
        "id": "ba1946b2"
      },
      "source": [
        "\n",
        "## it_nltmadj_01_enus_05"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e057fa",
      "metadata": {
        "id": "01e057fa"
      },
      "source": [
        "### Wordnet Relations & Semantic Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "6914d429",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6914d429",
        "outputId": "d64f5626-b7e1-4cea-b894-55534d3aa70b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\nukes\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw to\n",
            "[nltk_data]     C:\\Users\\nukes\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw') # The nltk's Open Multilingual Wordnet has English names for all the synsets, since it is a\n",
        "# multilingual database centered on the original English Wordnet\n",
        "\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526c8ad9",
      "metadata": {
        "id": "526c8ad9"
      },
      "source": [
        "#### Meronym\n",
        "A meronym denotes a member of something. Example, 'wheel' is a meronym of 'automobile'.\n",
        "\n",
        "Hypernyms and hyponyms are called lexical relations because they relate one synset to another. These two relations navigate up and down the \"is-a\" hierarchy. Another important way to navigate the WordNet network is from items to their components (meronyms) or to the things they are contained in (holonyms). For example, the parts of a tree are its trunk, crown, and so on; the part_meronyms(). The substance a tree is made of includes heartwood and sapwood; the substance_meronyms(). A collection of trees forms a forest; the member_holonyms():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "c6122ffb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6122ffb",
        "outputId": "7631ce4f-3164-40ec-eb4b-ce1b66b283e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "part_meronyms:  [Synset('burl.n.02'), Synset('crown.n.07'), Synset('limb.n.02'), Synset('stump.n.01'), Synset('trunk.n.01')]\n",
            "substance_meronyms:  [Synset('heartwood.n.01'), Synset('sapwood.n.01')]\n"
          ]
        }
      ],
      "source": [
        "syn_arr = wordnet.synsets('tree')\n",
        "print('part_meronyms: ',syn_arr[0].part_meronyms())\n",
        "print('substance_meronyms: ',syn_arr[0].substance_meronyms()) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edadb94f",
      "metadata": {
        "id": "edadb94f"
      },
      "source": [
        "#### Holonym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3cde126c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cde126c",
        "outputId": "e174cd95-a186-4f39-fffa-5128bc8b43bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "part_holonym:  [Synset('tree.n.01')]\n",
            "substance_holonym:  [Synset('tree.n.01')]\n"
          ]
        }
      ],
      "source": [
        "print('part_holonym: ',wordnet.synset('trunk.n.01').part_holonyms())\n",
        "print('substance_holonym: ',wordnet.synset('heartwood.n.01').substance_holonyms())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07d7abe8",
      "metadata": {
        "id": "07d7abe8"
      },
      "source": [
        "#### Entailments\n",
        "Semantic relationship between two verbs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f33184f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f33184f3",
        "outputId": "a6684a87-7da2-4692-cc23-eed7e21b0574"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('arouse.v.07'), Synset('disappoint.v.01')]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordnet.synset('tease.v.03').entailments()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cebe6bc5",
      "metadata": {
        "id": "cebe6bc5"
      },
      "source": [
        "#### Semantic Similarity\n",
        "To compute the similarity between two sentences, we base the semantic similarity between word senses. – synonyms and antonyms are one step in this direction.   \n",
        "\n",
        "Some similarity approaches can be found below.\n",
        "\n",
        "- Vector space model\n",
        " - Latent Semantic Analysis (LSA) or Latent Semantic Indexing (LSI)\n",
        "\n",
        "- Semantic (via WordNet)\n",
        " - Similarity measures (Pedersen et al.,)\n",
        "  - Path lengths between concepts\n",
        "   - lch (Leacock and Chodorow)\n",
        "   - wup (Wu and Palmer)\n",
        "   - path (path similarity)\n",
        "  - Information content\n",
        "   - res (Resnik)\n",
        "   - lin (Lin)\n",
        "   - jcn (Jiang and Conrath)\n",
        " - Measures of relatedness (Pedersen et al.,)\n",
        "  - hso (Hirst and St-Onge)\n",
        "  - lesk (Banerjee and Pedersen)\n",
        "  - vector (Patwardhan. Related to ‘vector space model’ above)\n",
        "- Possibly other approaches…\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fca193d5",
      "metadata": {
        "id": "fca193d5"
      },
      "source": [
        "Using WordNet, It can be calculated by *path_similarity()* function. It returns a score which denotes how similar two words are by traversing through WordNet network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a255736a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a255736a",
        "outputId": "c653f69b-f803-4fa0-b123-094e8c4801a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.125"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordnet.synset('bus.n.01').path_similarity(wordnet.synset('car.n.01'))\n",
        "wordnet.synset('water.n.01').path_similarity(wordnet.synset('sea.n.01'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "06a3082f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06a3082f",
        "outputId": "9168332b-782f-45f8-ca69-a464919cb6f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordnet.synset('car.n.01').path_similarity(wordnet.synset('car.n.01'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "250e9d74",
      "metadata": {
        "id": "250e9d74"
      },
      "source": [
        "#### Multilingual WordNet\n",
        "\n",
        "WordNet has one of the largest multilingual dictionary. It is even utilized by Google Translate as a part of the translation process between languages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "90361336",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90361336",
        "outputId": "144d4a80-3570-4e0f-b413-e44f094b769c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['eng']\n",
            "\n",
            "\n",
            "['mare']\n"
          ]
        }
      ],
      "source": [
        "print(sorted(wordnet.langs())) # List of languages supported by wordnet\n",
        "print('\\n')\n",
        "print(wordnet.synset('sea.n.01').lemma_names('ita')) # Example of translation into other languages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9355508c",
      "metadata": {
        "id": "9355508c"
      },
      "source": [
        "\n",
        "## it_nltmadj_01_enus_06"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56d14f4f",
      "metadata": {
        "id": "56d14f4f"
      },
      "source": [
        "### Sematic similarity of two sentences using WordNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6198df8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6198df8",
        "outputId": "e9ae06c2-40dc-4288-cdc1-9effe52f4cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Package omw is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw')\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "english_stopwords = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff772a1a",
      "metadata": {
        "id": "ff772a1a"
      },
      "outputs": [],
      "source": [
        "# This method is defined to remove the punctuations from the given text\n",
        "regular_punct = list(string.punctuation) # creating a list of punctuations \n",
        "def remove_punctuation(text,punct_list):\n",
        "    for punc in punct_list:\n",
        "        if punc in text:\n",
        "            text = text.replace(punc, ' ') # The replace method is used to replace a specific phrase with another\n",
        "    return text.strip() # The strip() method returns a copy of the string by removing both the leading and the trailing spaces "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de3a973",
      "metadata": {
        "id": "2de3a973"
      },
      "outputs": [],
      "source": [
        "def preprocess(sentence):\n",
        "    '''\n",
        "    Clean – remove punctuation characters and numbers.\n",
        "    Normalize – lowercase and expand contractions (don’t –> do not)\n",
        "    Lemmatization – obtain “root” words that can be found in a dictionary. This eliminates past and future tense words and provides present tense. \n",
        "    Also, any plural words are converted to singular.\n",
        "    Tokenization\n",
        "    Determine parts of speech\n",
        "    Remove stop words – these are low value words that occur so frequently they don’t offer any discriminating value to \n",
        "    determining the similarity between texts.\n",
        "    Obtain and save synsets for each sentence.\n",
        "    \n",
        "    '''\n",
        "    sentence = remove_punctuation(sentence,regular_punct)\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "    \n",
        "    # Filter stopwords\n",
        "    tagged_sentence_words = [word for word in tagged_tokens if word not in english_stopwords]\n",
        "    \n",
        "    synsets_list = []\n",
        "    ##get synsets\n",
        "    for word,pos in tagged_sentence_words:\n",
        "        \n",
        "        synsets = wn.synsets(word.lower() ,pos = 'n')\n",
        "        synsets_list.extend(synsets)\n",
        "    \n",
        "    return synsets_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d68af56f",
      "metadata": {
        "id": "d68af56f"
      },
      "outputs": [],
      "source": [
        "def SimScore(synsets1, synsets2):\n",
        "    \"\"\"\n",
        "    Purpose: Computes sentence similarity using Wordnet path_similarity().\n",
        "    Input: Synset lists representing sentence 1 and sentence 2.\n",
        "    Output: Similarity score as a float\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"-----\")\n",
        "    print(\"Synsets1: %s\\n\" % synsets1)\n",
        "    print(\"Synsets2: %s\\n\" % synsets2)\n",
        "\n",
        "    sumSimilarityscores = 0\n",
        "    scoreCount = 0\n",
        "\n",
        "    # For each synset in the first sentence...\n",
        "    for synset1 in synsets1:\n",
        "\n",
        "        synsetScore = 0\n",
        "        similarityScores = []\n",
        "\n",
        "        # For each synset in the second sentence...\n",
        "        for synset2 in synsets2:\n",
        "\n",
        "            # Only compare synsets with the same POS tag. Word to word knowledge\n",
        "            # measures cannot be applied across different POS tags.\n",
        "            if synset1.pos() == synset2.pos():\n",
        "\n",
        "                # Note below is the call to path_similarity mentioned above. \n",
        "                synsetScore = synset1.path_similarity(synset2)\n",
        "\n",
        "                if synsetScore < 1: #!= None:\n",
        "                    print(\"Path Score %0.2f: %s vs. %s\" % (synsetScore, synset1, synset2))\n",
        "                    similarityScores.append(synsetScore)\n",
        "\n",
        "                # If there are no similarity results but the SAME WORD is being\n",
        "                # compared then it gives a max score of 1.\n",
        "                elif synset1.name().split(\".\")[0] == synset2.name().split(\".\")[0]:\n",
        "                    synsetScore = 1\n",
        "                    print(\"Path MAX-Score %0.2f: %s vs. %s\" % (synsetScore, synset1, synset2))\n",
        "                    similarityScores.append(synsetScore)\n",
        "\n",
        "                synsetScore = 0\n",
        "\n",
        "        if(len(similarityScores) > 0):\n",
        "            sumSimilarityscores += max(similarityScores)\n",
        "            scoreCount += 1\n",
        "\n",
        "    # Average the summed, maximum similarity scored and return.\n",
        "    if scoreCount > 0:\n",
        "        avgScores = sumSimilarityscores / scoreCount\n",
        "\n",
        "    return avgScores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f326d179",
      "metadata": {
        "id": "f326d179"
      },
      "outputs": [],
      "source": [
        "sent1 = 'The Cardigan dog breed is superior.'\n",
        "sent2 = 'Pembroke breed is the best.'\n",
        "\n",
        "# Preprocess and extract synsets\n",
        "synsets1 = preprocess(sent1)\n",
        "synsets2 = preprocess(sent2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc044283",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc044283",
        "outputId": "aaae041f-f7cc-47f0-8a7a-b1e311da4ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Synset('cardigan.n.01'), Synset('cardigan.n.02'), Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('breed.n.01'), Synset('breed.n.02'), Synset('superior.n.01'), Synset('superior.n.02'), Synset('victor.n.01'), Synset('lake_superior.n.01'), Synset('superior.n.05'), Synset('superscript.n.01')]\n",
            "\n",
            "\n",
            "[Synset('pembroke.n.01'), Synset('breed.n.01'), Synset('breed.n.02'), Synset('best.n.01'), Synset('best.n.02'), Synset('best.n.03')]\n",
            "\n",
            "--------------------\n",
            "\n",
            "0.07142857142857142\n"
          ]
        }
      ],
      "source": [
        "print(synsets1)\n",
        "print('\\n')\n",
        "print(synsets2)\n",
        "print('\\n--------------------\\n')\n",
        "print(synsets1[0].path_similarity(synsets2[5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f287b06e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f287b06e",
        "outputId": "973ed532-6593-4b02-aa32-a3d8fdf0bdb2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'slightly bowlegged variety of corgi having rounded ears and a long tail'"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wn.synset('cardigan.n.01').definition()\n",
        "wn.synset('cardigan.n.02').definition()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab74ff0e",
      "metadata": {
        "id": "ab74ff0e"
      },
      "source": [
        "#### SimScore equation\n",
        "\n",
        ": image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5929d844",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5929d844",
        "outputId": "f0124d70-6b82-4ab2-c328-5c2526a45362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----\n",
            "Synsets1: [Synset('cardigan.n.01'), Synset('cardigan.n.02'), Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('breed.n.01'), Synset('breed.n.02'), Synset('superior.n.01'), Synset('superior.n.02'), Synset('victor.n.01'), Synset('lake_superior.n.01'), Synset('superior.n.05'), Synset('superscript.n.01')]\n",
            "\n",
            "Synsets2: [Synset('pembroke.n.01'), Synset('breed.n.01'), Synset('breed.n.02'), Synset('best.n.01'), Synset('best.n.02'), Synset('best.n.03')]\n",
            "\n",
            "Path Score 0.07: Synset('cardigan.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.07: Synset('cardigan.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.05: Synset('cardigan.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.06: Synset('cardigan.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.09: Synset('cardigan.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.07: Synset('cardigan.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.33: Synset('cardigan.n.02') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.06: Synset('cardigan.n.02') vs. Synset('breed.n.01')\n",
            "Path Score 0.05: Synset('cardigan.n.02') vs. Synset('breed.n.02')\n",
            "Path Score 0.06: Synset('cardigan.n.02') vs. Synset('best.n.01')\n",
            "Path Score 0.12: Synset('cardigan.n.02') vs. Synset('best.n.02')\n",
            "Path Score 0.09: Synset('cardigan.n.02') vs. Synset('best.n.03')\n",
            "Path Score 0.33: Synset('dog.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.07: Synset('dog.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.05: Synset('dog.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.06: Synset('dog.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.17: Synset('dog.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.11: Synset('dog.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.09: Synset('frump.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.08: Synset('frump.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('frump.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.07: Synset('frump.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.17: Synset('frump.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.11: Synset('frump.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.10: Synset('dog.n.03') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.08: Synset('dog.n.03') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('dog.n.03') vs. Synset('breed.n.02')\n",
            "Path Score 0.07: Synset('dog.n.03') vs. Synset('best.n.01')\n",
            "Path Score 0.20: Synset('dog.n.03') vs. Synset('best.n.02')\n",
            "Path Score 0.12: Synset('dog.n.03') vs. Synset('best.n.03')\n",
            "Path Score 0.10: Synset('cad.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.08: Synset('cad.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('cad.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.07: Synset('cad.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.20: Synset('cad.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.12: Synset('cad.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.06: Synset('frank.n.02') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.08: Synset('frank.n.02') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('frank.n.02') vs. Synset('breed.n.02')\n",
            "Path Score 0.07: Synset('frank.n.02') vs. Synset('best.n.01')\n",
            "Path Score 0.10: Synset('frank.n.02') vs. Synset('best.n.02')\n",
            "Path Score 0.08: Synset('frank.n.02') vs. Synset('best.n.03')\n",
            "Path Score 0.07: Synset('pawl.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.07: Synset('pawl.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.05: Synset('pawl.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.06: Synset('pawl.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.09: Synset('pawl.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.07: Synset('pawl.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.08: Synset('andiron.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.07: Synset('andiron.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.05: Synset('andiron.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.06: Synset('andiron.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.10: Synset('andiron.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.08: Synset('andiron.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.06: Synset('breed.n.01') vs. Synset('pembroke.n.01')\n",
            "Path MAX-Score 1.00: Synset('breed.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.07: Synset('breed.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.09: Synset('breed.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.10: Synset('breed.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.08: Synset('breed.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.05: Synset('breed.n.02') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.07: Synset('breed.n.02') vs. Synset('breed.n.01')\n",
            "Path MAX-Score 1.00: Synset('breed.n.02') vs. Synset('breed.n.02')\n",
            "Path Score 0.07: Synset('breed.n.02') vs. Synset('best.n.01')\n",
            "Path Score 0.07: Synset('breed.n.02') vs. Synset('best.n.02')\n",
            "Path Score 0.06: Synset('breed.n.02') vs. Synset('best.n.03')\n",
            "Path Score 0.11: Synset('superior.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.09: Synset('superior.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('superior.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.08: Synset('superior.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.25: Synset('superior.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.14: Synset('superior.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.10: Synset('superior.n.02') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.08: Synset('superior.n.02') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('superior.n.02') vs. Synset('breed.n.02')\n",
            "Path Score 0.07: Synset('superior.n.02') vs. Synset('best.n.01')\n",
            "Path Score 0.20: Synset('superior.n.02') vs. Synset('best.n.02')\n",
            "Path Score 0.12: Synset('superior.n.02') vs. Synset('best.n.03')\n",
            "Path Score 0.11: Synset('victor.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.09: Synset('victor.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('victor.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.08: Synset('victor.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.25: Synset('victor.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.14: Synset('victor.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.07: Synset('lake_superior.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.09: Synset('lake_superior.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('lake_superior.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.08: Synset('lake_superior.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.12: Synset('lake_superior.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.09: Synset('lake_superior.n.01') vs. Synset('best.n.03')\n",
            "Path Score 0.06: Synset('superior.n.05') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.07: Synset('superior.n.05') vs. Synset('breed.n.01')\n",
            "Path Score 0.05: Synset('superior.n.05') vs. Synset('breed.n.02')\n",
            "Path Score 0.06: Synset('superior.n.05') vs. Synset('best.n.01')\n",
            "Path Score 0.08: Synset('superior.n.05') vs. Synset('best.n.02')\n",
            "Path Score 0.07: Synset('superior.n.05') vs. Synset('best.n.03')\n",
            "Path Score 0.06: Synset('superscript.n.01') vs. Synset('pembroke.n.01')\n",
            "Path Score 0.09: Synset('superscript.n.01') vs. Synset('breed.n.01')\n",
            "Path Score 0.06: Synset('superscript.n.01') vs. Synset('breed.n.02')\n",
            "Path Score 0.08: Synset('superscript.n.01') vs. Synset('best.n.01')\n",
            "Path Score 0.08: Synset('superscript.n.01') vs. Synset('best.n.02')\n",
            "Path Score 0.07: Synset('superscript.n.01') vs. Synset('best.n.03')\n"
          ]
        }
      ],
      "source": [
        "scores = SimScore(synsets1, synsets2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432beaa0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "432beaa0",
        "outputId": "0b0e6308-8312-499d-c003-e550433a817a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Func Score: 0.27\n"
          ]
        }
      ],
      "source": [
        "print(\"Func Score: %0.2f\" % scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec72f33f",
      "metadata": {
        "id": "ec72f33f"
      },
      "source": [
        "\n",
        "## it_nltmadj_01_enus_07"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f75a9799",
      "metadata": {
        "id": "f75a9799"
      },
      "source": [
        "### **Regular Expressions**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "992c4e35",
      "metadata": {
        "id": "992c4e35"
      },
      "source": [
        "**Regular expressions** (REs, or regexes, or regex patterns) are a powerful language for matching text patterns. Useful for searches, e.g., E-mail addresses or phone numbers. This notebook includes basic introduction to regular expressions and its implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de80b3a1",
      "metadata": {
        "id": "de80b3a1"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3311528e",
      "metadata": {
        "id": "3311528e"
      },
      "source": [
        "To define our pattern, use re.compile() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1373c248",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1373c248",
        "outputId": "aa62ebba-1634-4bf9-b411-cac09b64c0b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "re.compile('abc')\n"
          ]
        }
      ],
      "source": [
        "test_string = '123abc456789abc123ABC'\n",
        "pattern = re.compile(r'abc')\n",
        "print(pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14961c57",
      "metadata": {
        "id": "14961c57"
      },
      "source": [
        "Some **search methods** in regex are:\n",
        "- match(): Determine if the RE matches at the beginning of the string.\n",
        "- search(): Scan through a string, looking for any location where this RE matches.\n",
        "- findall(): Find all substrings where the RE matches, and returns them as a list.\n",
        "- finditer(): Find all substrings where the RE matches, and returns them as an iterator.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4NmqfeSKqSYr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NmqfeSKqSYr",
        "outputId": "5b145fd0-a804-41dd-fce6-006919be1503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(0, 3), match='abc'>\n"
          ]
        }
      ],
      "source": [
        "# match\n",
        "my_string = 'abc123ABC123abc'\n",
        "pattern = re.compile(r'abc')\n",
        "match = pattern.match(my_string)\n",
        "print(match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LjqhSvg7repH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjqhSvg7repH",
        "outputId": "a50dc68c-7a6f-4dc1-f1a3-0340bd65a9f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# match\n",
        "my_string = 'abc123ABC123abc'\n",
        "pattern = re.compile(r'123')\n",
        "match = pattern.match(my_string)\n",
        "print(match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6EjycsU3rMXG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EjycsU3rMXG",
        "outputId": "2110d600-96d0-49e2-fbde-0296554e8dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(15, 18), match='DOG'>\n"
          ]
        }
      ],
      "source": [
        "# Search\n",
        "my_string = 'abc123ABC123abcDOG'\n",
        "pattern = re.compile(r'DOG')\n",
        "match = pattern.search(my_string)\n",
        "print(match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vGF8HGbarbup",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGF8HGbarbup",
        "outputId": "bb24ef25-0dda-4f54-8f91-e56ea5a1bd5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(3, 6), match='123'>\n"
          ]
        }
      ],
      "source": [
        "# Search\n",
        "my_string = 'abc123ABC123abc'\n",
        "pattern = re.compile(r'123')\n",
        "match = pattern.search(my_string)\n",
        "print(match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d6f7f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27d6f7f5",
        "outputId": "a13c3941-92d6-446a-f060-fa6fa97d9463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['123', '123']\n",
            "123\n",
            "123\n"
          ]
        }
      ],
      "source": [
        "# findall()\n",
        "my_string = 'abc123ABC123abc'\n",
        "pattern = re.compile(r'123')\n",
        "matches = pattern.findall(my_string)\n",
        "print(matches)\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf849c09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf849c09",
        "outputId": "68b9261a-a22c-4699-ea13-955f7dc3e4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(3, 6), match='abc'>\n",
            "<re.Match object; span=(12, 15), match='abc'>\n"
          ]
        }
      ],
      "source": [
        "# finditer()\n",
        "test_string = '123abc456789abc123ABC'\n",
        "matches = re.finditer(r'abc', test_string)\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ilgAcGR7URKm",
      "metadata": {
        "id": "ilgAcGR7URKm"
      },
      "source": [
        "# it_nltmadj_01_enus_08"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fbc27df",
      "metadata": {
        "id": "5fbc27df"
      },
      "source": [
        "#### Subfeatures under Match object\n",
        "\n",
        "- group(): Return the string matched by the RE\n",
        "- start(): Return the starting position of the match\n",
        "- end(): Return the ending position of the match\n",
        "- span(): Return a tuple containing the (start, end) positions of the match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a7d3dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35a7d3dc",
        "outputId": "fce7300a-4c68-4c5f-c366-2a688b9e9c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(0, 3), match='abc'>\n",
            "(0, 3) 0 3\n",
            "abc\n",
            "<re.Match object; span=(12, 15), match='abc'>\n",
            "(12, 15) 12 15\n",
            "abc\n"
          ]
        }
      ],
      "source": [
        "my_string = 'abc123ABC123abc'\n",
        "pattern = re.compile(r'abc')\n",
        "matches = pattern.finditer(my_string)\n",
        "for match in matches:\n",
        "    print(match)\n",
        "    print(match.span(), match.start(), match.end())\n",
        "    print(match.group()) # returns the string"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c8fb833",
      "metadata": {
        "id": "9c8fb833"
      },
      "source": [
        "#### Meta characters\n",
        "Metacharacters are characters with a special meaning:\n",
        "It includes . ^ $ * + ? { } [ ] \\ | ( )\n",
        "\n",
        "- . Any character (except newline character) \"he..o\"\n",
        "- ^ Starts with \"^hello\"\n",
        "- $ Ends with \"world$\"\n",
        "-(*) Zero or more occurrences \"aix *\"\n",
        "- (+) One or more occurrences \"aix+\"\n",
        "- { } Exactly the specified number of occurrences \"al{2}\"\n",
        "- [] A set of characters \"[a-m]\"\n",
        "- \\ Signals a special sequence (can also be used to escape special characters) \"\\d\"\n",
        "- | Either or \"falls|stays\"\n",
        "- ( ) Capture and group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b55949bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b55949bf",
        "outputId": "d938b434-6f28-480a-da14-a5733c0b69e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(4, 5), match='.'>\n"
          ]
        }
      ],
      "source": [
        "test_string = 'demo.com'\n",
        "pattern = re.compile(r'\\.')\n",
        "matches = pattern.finditer(test_string)\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06301225",
      "metadata": {
        "id": "06301225"
      },
      "source": [
        "#### More Metacharacters / Special Sequences\n",
        "\n",
        "Special Metacharacters: '\\' followed by characters\n",
        "\n",
        "- \\d :Matches any decimal digit; this is equivalent to the class [0-9].\n",
        "- \\D : Matches any non-digit character; this is equivalent to the class [^0-9].\n",
        "- \\s : Matches any whitespace character;\n",
        "- \\S : Matches any non-whitespace character;\n",
        "- \\w : Matches any alphanumeric (word) character; this is equivalent to the class [a-zA-Z0-9_].\n",
        "- \\W : Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].\n",
        "- \\b Returns a match where the specified characters are at the beginning or at the end of a word r\"\\bain\" r\"ain\\b\"\n",
        "- \\B Returns a match where the specified characters are present, but NOT at the beginning (or at the end) of a word r\"\\Bain\" r\"ain\\B\"\n",
        "- \\A Returns a match if the specified characters are at the beginning of the string \"\\AThe\"\n",
        "- \\Z Returns a match if the specified characters are at the end of the string \"Spain\\Z\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4331934",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4331934",
        "outputId": "6ce92fcc-faae-4ac0-96cc-3f40dd832737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(22, 23), match='1'>\n",
            "<re.Match object; span=(23, 24), match='2'>\n",
            "<re.Match object; span=(24, 25), match='3'>\n",
            "<re.Match object; span=(25, 26), match='4'>\n",
            "<re.Match object; span=(26, 27), match='5'>\n",
            "\n",
            "<re.Match object; span=(4, 5), match=' '>\n",
            "<re.Match object; span=(7, 8), match=' '>\n",
            "<re.Match object; span=(12, 13), match=' '>\n",
            "<re.Match object; span=(19, 20), match=' '>\n",
            "<re.Match object; span=(21, 22), match=' '>\n"
          ]
        }
      ],
      "source": [
        "test_string = 'This is demo string - 12345'\n",
        "pattern = re.compile(r'\\d')\n",
        "matches = pattern.finditer(test_string)\n",
        "for match in matches:\n",
        "    print(match)\n",
        "\n",
        "print()\n",
        "pattern = re.compile(r'\\s')\n",
        "matches = pattern.finditer(test_string)\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "741436b7",
      "metadata": {
        "id": "741436b7"
      },
      "source": [
        "#### Quantifier\n",
        "- (*) : 0 or more\n",
        "- (+) : 1 or more\n",
        "- ? : 0 or 1, used when a character can be optional\n",
        "- {4} : exact number\n",
        "- {4,6} : range numbers (min, max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b6f04d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47b6f04d",
        "outputId": "04ebe8f3-3729-4dbb-c85f-cbd8e40334f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(0, 0), match=''>\n",
            "<re.Match object; span=(1, 1), match=''>\n",
            "<re.Match object; span=(2, 2), match=''>\n",
            "<re.Match object; span=(3, 3), match=''>\n",
            "<re.Match object; span=(4, 4), match=''>\n",
            "<re.Match object; span=(5, 8), match='_12'>\n",
            "<re.Match object; span=(8, 8), match=''>\n",
            "\n",
            "--------------\n",
            "<re.Match object; span=(6, 8), match='12'>\n",
            "\n",
            "--------------\n"
          ]
        }
      ],
      "source": [
        "my_string = 'hello_12'\n",
        "pattern = re.compile(r'_?\\d*')\n",
        "matches = pattern.finditer(my_string)\n",
        "for match in matches:\n",
        "    print(match)\n",
        "\n",
        "print('\\n--------------')\n",
        "pattern = re.compile(r'\\d+')\n",
        "matches = pattern.finditer(my_string)\n",
        "for match in matches:\n",
        "    print(match)\n",
        "\n",
        "print('\\n--------------')   \n",
        "pattern = re.compile(r'\\d{3}') # or if you need a range r'\\d{3,5}'\n",
        "matches = pattern.finditer(my_string)\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sRLu_C3ApBaJ",
      "metadata": {
        "id": "sRLu_C3ApBaJ"
      },
      "source": [
        "## it_nltmadj_01_enus_09"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8fa3e2",
      "metadata": {
        "id": "7f8fa3e2"
      },
      "source": [
        "#### Conditions\n",
        "Use the | for either or condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725e70ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "725e70ab",
        "outputId": "513b1c79-fba3-40ed-e8cb-3d4ee525608a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(1, 12), match='Mr. Simpson'>\n",
            "<re.Match object; span=(25, 34), match='Mr. Brown'>\n",
            "<re.Match object; span=(44, 49), match='Mr. T'>\n",
            "\n",
            "----------------\n",
            "<re.Match object; span=(1, 12), match='Mr. Simpson'>\n",
            "<re.Match object; span=(13, 24), match='Mrs Simpson'>\n",
            "<re.Match object; span=(25, 34), match='Mr. Brown'>\n",
            "<re.Match object; span=(35, 43), match='Ms Smith'>\n",
            "<re.Match object; span=(44, 49), match='Mr. T'>\n"
          ]
        }
      ],
      "source": [
        "my_string = \"\"\"\n",
        "Mr. Simpson\n",
        "Mrs Simpson\n",
        "Mr. Brown\n",
        "Ms Smith\n",
        "Mr. T\n",
        "\"\"\"\n",
        "pattern = re.compile(r'Mr\\.?\\s\\w+')\n",
        "matches = pattern.finditer(my_string)\n",
        "for match in matches:\n",
        "    print(match)\n",
        "\n",
        "print('\\n----------------')\n",
        "pattern = re.compile(r'(Mr|Ms|Mrs)\\.?\\s\\w+')\n",
        "matches = pattern.finditer(my_string)\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26c4e19a",
      "metadata": {
        "id": "26c4e19a"
      },
      "source": [
        "#### Compilation Flags\n",
        "- ASCII, A : Makes several escapes like \\w, \\b, \\s and \\d match only on ASCII characters with the respective property.\n",
        "- DOTALL, S : Make . match any character, including newlines.\n",
        "- IGNORECASE, I : Do case-insensitive matches.\n",
        "- LOCALE, L : Do a locale-aware match.\n",
        "- MULTILINE, M : Multi-line matching, affecting ^ and $.\n",
        "- VERBOSE, X (for ‘extended’) : Enable verbose REs, which can be organized more cleanly and understandably."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec8aaa3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ec8aaa3",
        "outputId": "743b695e-c5ef-4b73-ca59-c0cb86bdfd49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<re.Match object; span=(6, 11), match='World'>\n"
          ]
        }
      ],
      "source": [
        "my_string = \"Hello World\"\n",
        "pattern = re.compile(r'world', re.IGNORECASE) # No match without I flag\n",
        "matches = pattern.finditer(my_string)\n",
        "for match in matches:\n",
        "    print(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38fd3249",
      "metadata": {
        "id": "38fd3249"
      },
      "source": [
        "## it_nltmadj_01_enus_10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a6caca",
      "metadata": {
        "id": "00a6caca"
      },
      "source": [
        "### Sentiment extraction using SentiWordNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0C_UhMYzdIIN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C_UhMYzdIIN",
        "outputId": "73e37af5-b77e-4884-a789-e452a61010b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"sentiwordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7WaNyByUc0VK",
      "metadata": {
        "id": "7WaNyByUc0VK"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import sentiwordnet as swn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KxpuH0zsdGQY",
      "metadata": {
        "id": "KxpuH0zsdGQY"
      },
      "outputs": [],
      "source": [
        "sent = swn.senti_synset('good.n.03')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hr_C9oDLdaBa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr_C9oDLdaBa",
        "outputId": "c0948dc3-8f14-4bb1-fd3b-18bb62801cef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent.pos_score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yZkcI81Yddkr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZkcI81Yddkr",
        "outputId": "a05a7efe-9808-4756-f82f-7c0da6c67d36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent.neg_score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N-lM8tcidgT-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-lM8tcidgT-",
        "outputId": "46108357-3310-4cc6-db7d-205e58af8bcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.375"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#1.0 - (pos_score + neg_score)\n",
        "sent.obj_score()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b657531f",
      "metadata": {
        "id": "b657531f"
      },
      "source": [
        "\n",
        "## it_nltmadj_01_enus_11"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deec43f7",
      "metadata": {
        "id": "deec43f7"
      },
      "source": [
        "### Sentiment Classification Using SentiWordNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jL3I79CUYIPa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL3I79CUYIPa",
        "outputId": "33815743-9095-46ec-d9e5-396e1ce1f85b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"sentiwordnet\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def penn_to_wn(tag):\n",
        "    \"\"\"\n",
        "    English Penn Treebank part-of-speech Tagset\n",
        "    \n",
        "    A tagset is a list of part-of-speech tags, i.e. labels used to indicate the part of speech and often also other grammatical \n",
        "    categories (case, tense etc.) of each token in a text corpus.\n",
        "    Convert between the PennTreebank tags to simple Wordnet tags\n",
        "    \"\"\"\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_sentiment(word,tag):\n",
        "    \"\"\" returns list of pos neg and objective score. But returns empty list if not present in senti wordnet. \"\"\"\n",
        "\n",
        "    wn_tag = penn_to_wn(tag)\n",
        "    if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
        "        return []\n",
        "\n",
        "    lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "    if not lemma:\n",
        "        return []\n",
        "\n",
        "    synsets = wn.synsets(word, pos=wn_tag)\n",
        "    if not synsets:\n",
        "        return []\n",
        "\n",
        "    # Take the first sense, the most common\n",
        "    synset = synsets[0]\n",
        "    swn_synset = swn.senti_synset(synset.name())\n",
        "\n",
        "    return [swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XDcd4G3wYaB9",
      "metadata": {
        "id": "XDcd4G3wYaB9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/LearnDataSci/articles/master/Python%20Pandas%20Tutorial%20A%20Complete%20Introduction%20for%20Beginners/IMDB-Movie-Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rNARqE4ZZbRs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "rNARqE4ZZbRs",
        "outputId": "761ac3eb-d6a9-4646-c804-58092539c9b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-24fb098d-5438-424a-895e-b966ae7d3802\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Description</th>\n",
              "      <th>Director</th>\n",
              "      <th>Actors</th>\n",
              "      <th>Year</th>\n",
              "      <th>Runtime (Minutes)</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Votes</th>\n",
              "      <th>Revenue (Millions)</th>\n",
              "      <th>Metascore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Guardians of the Galaxy</td>\n",
              "      <td>Action,Adventure,Sci-Fi</td>\n",
              "      <td>A group of intergalactic criminals are forced ...</td>\n",
              "      <td>James Gunn</td>\n",
              "      <td>Chris Pratt, Vin Diesel, Bradley Cooper, Zoe S...</td>\n",
              "      <td>2014</td>\n",
              "      <td>121</td>\n",
              "      <td>8.1</td>\n",
              "      <td>757074</td>\n",
              "      <td>333.13</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Prometheus</td>\n",
              "      <td>Adventure,Mystery,Sci-Fi</td>\n",
              "      <td>Following clues to the origin of mankind, a te...</td>\n",
              "      <td>Ridley Scott</td>\n",
              "      <td>Noomi Rapace, Logan Marshall-Green, Michael Fa...</td>\n",
              "      <td>2012</td>\n",
              "      <td>124</td>\n",
              "      <td>7.0</td>\n",
              "      <td>485820</td>\n",
              "      <td>126.46</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Split</td>\n",
              "      <td>Horror,Thriller</td>\n",
              "      <td>Three girls are kidnapped by a man with a diag...</td>\n",
              "      <td>M. Night Shyamalan</td>\n",
              "      <td>James McAvoy, Anya Taylor-Joy, Haley Lu Richar...</td>\n",
              "      <td>2016</td>\n",
              "      <td>117</td>\n",
              "      <td>7.3</td>\n",
              "      <td>157606</td>\n",
              "      <td>138.12</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Sing</td>\n",
              "      <td>Animation,Comedy,Family</td>\n",
              "      <td>In a city of humanoid animals, a hustling thea...</td>\n",
              "      <td>Christophe Lourdelet</td>\n",
              "      <td>Matthew McConaughey,Reese Witherspoon, Seth Ma...</td>\n",
              "      <td>2016</td>\n",
              "      <td>108</td>\n",
              "      <td>7.2</td>\n",
              "      <td>60545</td>\n",
              "      <td>270.32</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Suicide Squad</td>\n",
              "      <td>Action,Adventure,Fantasy</td>\n",
              "      <td>A secret government agency recruits some of th...</td>\n",
              "      <td>David Ayer</td>\n",
              "      <td>Will Smith, Jared Leto, Margot Robbie, Viola D...</td>\n",
              "      <td>2016</td>\n",
              "      <td>123</td>\n",
              "      <td>6.2</td>\n",
              "      <td>393727</td>\n",
              "      <td>325.02</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24fb098d-5438-424a-895e-b966ae7d3802')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24fb098d-5438-424a-895e-b966ae7d3802 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24fb098d-5438-424a-895e-b966ae7d3802');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Rank                    Title  ... Revenue (Millions) Metascore\n",
              "0     1  Guardians of the Galaxy  ...             333.13      76.0\n",
              "1     2               Prometheus  ...             126.46      65.0\n",
              "2     3                    Split  ...             138.12      62.0\n",
              "3     4                     Sing  ...             270.32      59.0\n",
              "4     5            Suicide Squad  ...             325.02      40.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tDsc1D8TYYXO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDsc1D8TYYXO",
        "outputId": "e5708bfe-c687-44e5-bbdc-84db754f2abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A group of intergalactic criminals are forced to work together to stop a fanatical warrior from taking control of the universe.\n"
          ]
        }
      ],
      "source": [
        "# Running sentiment for single Movie Plot \n",
        "ps = PorterStemmer()\n",
        "words_data = data['Description'][0].split()\n",
        "print(data['Description'][0])\n",
        "# words_data = [ps.stem(x) for x in words_data] # if you want to further stem the word\n",
        "\n",
        "pos_val = nltk.pos_tag(words_data)\n",
        "senti_val = [get_sentiment(x,y) for (x,y) in pos_val]\n",
        "\n",
        "sentiment =  sum([eachlist[2] for eachlist in senti_val if eachlist])/len(words_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sNEyFOG-YKeK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNEyFOG-YKeK",
        "outputId": "3ffa112d-da42-4b73-9b26-af6443747175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pos_val is [('A', 'DT'), ('group', 'NN'), ('of', 'IN'), ('intergalactic', 'JJ'), ('criminals', 'NNS'), ('are', 'VBP'), ('forced', 'VBN'), ('to', 'TO'), ('work', 'VB'), ('together', 'RB'), ('to', 'TO'), ('stop', 'VB'), ('a', 'DT'), ('fanatical', 'JJ'), ('warrior', 'NN'), ('from', 'IN'), ('taking', 'VBG'), ('control', 'NN'), ('of', 'IN'), ('the', 'DT'), ('universe.', 'NN')]\n",
            "senti_val for each word is [[], [0.0, 0.0, 1.0], [], [0.0, 0.0, 1.0], [0.0, 0.25, 0.75], [], [], [], [], [0.0, 0.0, 1.0], [], [], [], [0.375, 0.5, 0.125], [0.0, 0.0, 1.0], [], [], [0.0, 0.0, 1.0], [], [], []]\n",
            "Total sentiment is 0.27976190476190477\n"
          ]
        }
      ],
      "source": [
        "print(f\"pos_val is {pos_val}\")\n",
        "print(f\"senti_val for each word is {senti_val}\")\n",
        "print(f\"Total sentiment is {sentiment}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "it_nltmadj_01_enus.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
